
# FedLearning

En ce qui concerne les datasets utilisés, ils sont disponibles aux adresses suivantes : 

- Dataset de pneumonie : https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia (https://pubmed.ncbi.nlm.nih.gov/29474911/)
- Dataset de pneumothorax (poisonning attack simulation) : https://www.kaggle.com/competitions/siim-acr-pneumothorax-segmentation/
- Dataset de MRI de cerveau (poisonning attack simulation) : https://figshare.com/articles/dataset/brain_tumor_dataset/1512427

Pour ce qui est du framework de benchmarking easyFL, comme je vous l'avais dit lors de nos réunions, il est encore très récent et a très fortement évolué tout au long du travail (plus de 150 commits pendant cette durée). J'ai d'abord commencé les expérimentations avec une version plus ancienne (d'il y a 3,4 mois) (dossier "easyFL_old"), puis j'ai plus tard continué les expérimentations avec une version plus récente qui résolvait pas mal de bugs et qui ajoutait également de nouvelles fonctionnalités.

Dans la première version (dossier "easyFL_old"), je générais les datasets de benchmarking en utilisant la technique #2 (les deux techniques sont expliquées à la ligne 534 de https://github.com/212515005/FedLearning/blob/main/easyFL/benchmark/toolkits.py) qui consistait à copier et enregistrer les données partitionnées dans un fichier json sous forme de tensors. Cependant, les fichiers json générés étaient beaucoup trop lourds (plus de 20Go pour chaque simulation), et le simple fait d'ouvrir le fichier json lors des simulations mettait plus de 30 minutes... Dans cette première version, j'ai utilisé le benchmark "emnist" (https://github.com/212515005/FedLearning/tree/main/easyFL_old/benchmark/emnist) que j'ai modifié pour pouvoir utiliser mes données X-ray à la place et effectuer de la classification binaire (via le core.py de ce dossier) et j'ai modifié le cnn de base avec mon modèle (via cnn.py du dossier model). Je n'ai pas modifié les noms des benchmarks et c'est pour cela qu'ils s'appellent toujours "emnist_...".

J'ai donc finalement décidé au cours du travail d'utiliser une version plus récente (dossier "easyFL") et d'utiliser la technique #1 qui consiste à enregistrer les indices des images uniquement plutôt que de copier et enregistrer toutes les données pour chaque simulation. Les données sont alors importées dynamiquement depuis le dossier d'origine lors de l'exécution des simulations. Dans cette deuxième version, j'ai cette fois utilisé le benchmark "cifar10_classification" (https://github.com/212515005/FedLearning/tree/main/easyFL/benchmark/cifar10_classification) qui implémentait cette technique #1. Je l'ai également modifié pour pouvoir utiliser mes données X-ray à la place (via le core.py de ce dossier). A noter que cette fois j'ai appliqué le préprocessing des images manuellement à l'avance pour ne pas devoir le refaire lors de chaque simulation et du coup économiser du temps de calcul. Et j'ai également modifié le cnn de base avec mon modèle (via cnn.py du dossier model). Je n'ai encore une fois pas modifié les noms des benchmarks et c'est pour cela qu'ils s'appellent toujours "cifar10_classification_...".

Je viens d'aller regarder le Github du framework (https://github.com/WwZzz/easyFL) et il a encore fortement évolué depuis ma deuxième version utilisée (qui date d'avril). En lisant les descriptions des commits, je vois que beaucoup de bugs ont été résolus et des fonctionnalités ont été ajoutées. Je crois qu'il serait donc intéressant de partir de cette version "plus finale" si vous voulez encore effectuer des expérimentations en utilisant ce framework. Et surtout, je vous recommande d'utiliser la technique #1 comme je l'ai finalement fait, l'utilisation de la technique #2 entraîne la création de fichiers vraiment énormes pour chaque simulation et les temps de simulation sont aussi beaucoup plus longs dû aux temps d'ouverture de ces gros fichiers.

En ce qui concerne les expérimentations effectuées sur Flower, il n'y a pas grand chose de particulier à rajouter à part le fait que j'ai utilisé la version 0.15.0 d'Opacus pour la differential privacy plutôt que la 1.1.2 actuelle. Si jamais vous voulez utiliser la version plus récente, l'implémentation est légèrement différente comme expliqué ici : https://github.com/pytorch/opacus/blob/main/Migration_Guide.md.
